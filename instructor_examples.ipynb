{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output structured using an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to configure a key in:\n",
    "\n",
    "https://platform.openai.com/api-keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import instructor\n",
    "from typing import Union\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_AP'))\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator, model_validator\n",
    "from typing import ClassVar\n",
    "\n",
    "# Patch the OpenAI client\n",
    "client = instructor.from_openai(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we can leverage pydantic to define a schema desired in response to our model, and also implement some basic validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserInfo(BaseModel):\n",
    "    country: str = Field(description=\"The country where the user is located\")\n",
    "    city: str = Field(description=\"The unique identifier for the city where the user is located\")\n",
    "    language: str = Field(description=\"The primary language spoken by the user\")\n",
    "    age: int= Field(...,description=\"The age of the user\", gt=0, lt=120)\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"country\": \"united states\",\n",
    "                    \"city\": \"new york\",\n",
    "                    \"language\": \"english\",\n",
    "                    \"age\": 30\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'united states', 'city': 'miami', 'language': 'english', 'age': 119}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=UserInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Please identify entities in the input of user\"},\n",
    "        {\"role\": \"user\", \"content\": \"I am Eduardo from Miami, United States and I speak English, I am 200\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose we need to enforce for any particular reason the output as UPPERCASE.So we can deep dive in validation of pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    country: str = Field(description=\"The country where the user is located\")\n",
    "    city: str = Field(description=\"The unique identifier for the city where the user is located\")\n",
    "    language: str = Field(description=\"The primary language spoken by the user\")\n",
    "    age: int= Field(...,description=\"The age of the user\", gt=0, lt=120)\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"country\": \"united state\",\n",
    "                    \"city\": \"new york\",\n",
    "                    \"language\": \"english\",\n",
    "                    \"age\": 30\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @field_validator('country', 'city', 'language')\n",
    "    @classmethod\n",
    "    def validate_and_uppercase_fields(cls, value: str) -> str:\n",
    "        return value.upper()\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_age(self) -> 'UserInfo':\n",
    "        if self.age <= 0 or self.age >= 120:\n",
    "            raise ValueError('Age must be between 1 and 119')\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'UNITED STATES', 'city': 'MIAMI', 'language': 'ENGLISH', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=UserInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Please identify entities in the input of user\"},\n",
    "        {\"role\": \"user\", \"content\": \"I am Eduardo from Miami, United States and I speak English, also i am -200 year old\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we notice we, enforce our output as we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class SentimentEnum(str, Enum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "\n",
    "class TextInfo(BaseModel):\n",
    "    sentiment: SentimentEnum = Field(description=\"The sentiment of the text\")\n",
    "    length_of_text: int = Field(description=\"The length of the text in characters\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"sentiment\": \"positive\",\n",
    "                    \"length_of_text\": 123\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_length_of_text(self) -> 'TextInfo':\n",
    "        if self.length_of_text <= 0:\n",
    "            raise ValueError('Length of text must be positive')\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': <SentimentEnum.POSITIVE: 'positive'>, 'length_of_text': 66}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=TextInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Indentifica el sentiemiento y la longitud del texto\"},\n",
    "        {\"role\": \"user\", \"content\": \"El dia de hoy fue un dia muy bueno, me siento muy feliz\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': <SentimentEnum.NEUTRAL: 'neutral'>, 'length_of_text': 55}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=TextInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Indentifica el sentiemiento y la longitud del texto\"},\n",
    "        {\"role\": \"user\", \"content\": \"La verdad hoy me he sentido algo triste, no se que hacer\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ListSchema(BaseModel):\n",
    "    feelings: List[str] = Field(description=\"A list of string items\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"feelings\": [\"happy\", \"sad\", \"angry\", \"excited\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feelings': ['molesto', 'enojado', 'frustrado']}\n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"\"\"actua como un identificador de identidades y lista los sentimientos en los chats escritos por los usuarios\n",
    "solo identifica las entidades en el texto\n",
    "\"\"\"\n",
    "\n",
    "prompt_user = \"\"\"Me comunicque ayer para si me podrian ayudar con el problema de conexion pero la atencion no fue nada buena, estoy muy molesto y enojado,\n",
    "luego me pasaron a otro operador y luego otro, la verdad termin√© frustrado\n",
    "\"\"\"\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=ListSchema,\n",
    "    messages= [{\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt_user}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice we can restricted our ouput as a list of feeling in spanish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

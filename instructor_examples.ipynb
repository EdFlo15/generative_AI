{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output structured using an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to configure a key in:\n",
    "\n",
    "https://platform.openai.com/api-keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import instructor\n",
    "from typing import Union\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_AP'))\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator, model_validator\n",
    "from typing import ClassVar\n",
    "\n",
    "# Patch the OpenAI client\n",
    "client = instructor.from_openai(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we can leverage pydantic to define a schema desired in response to our model, and also implement some basic validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserInfo(BaseModel):\n",
    "    country: str = Field(description=\"The country where the user is located\")\n",
    "    city: str = Field(description=\"The unique identifier for the city where the user is located\")\n",
    "    language: str = Field(description=\"The primary language spoken by the user\")\n",
    "    age: int= Field(...,description=\"The age of the user\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"country\": \"united states\",\n",
    "                    \"city\": \"new york\",\n",
    "                    \"language\": \"english\",\n",
    "                    \"age\": 30\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'United States', 'city': 'Miami', 'language': 'English', 'age': 21}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=UserInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Please identify entities in the input of user\"},\n",
    "        {\"role\": \"user\", \"content\": \"I am Eduardo, I am from Miami United States and I speak English, I am 21\"}\n",
    "    ],\n",
    "    max_retries=4\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain scenarios, it may be necessary to enforce the output to be in UPPERCASE. To achieve this, we can leverage the validation capabilities provided by Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    country: str = Field(description=\"The country where the user is located\")\n",
    "    city: str = Field(description=\"The unique identifier for the city where the user is located\")\n",
    "    language: str = Field(description=\"The primary language spoken by the user\")\n",
    "    age: int = Field(description=\"The age of the user\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"country\": \"united state\",\n",
    "                    \"city\": \"new york\",\n",
    "                    \"language\": \"english\",\n",
    "                    \"age\": 30\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @field_validator('country', 'city', 'language')\n",
    "    @classmethod\n",
    "    def validate_and_uppercase_fields(cls, value: str) -> str:\n",
    "        return value.upper()\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_age(self) -> 'UserInfo':\n",
    "        if self.age <= 0 or self.age >= 120:\n",
    "            self.age = 18  # Set default value if age is out of range\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'UNITED STATES', 'city': 'MIAMI', 'language': 'ENGLISH', 'age': 18}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=UserInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Please identify entities in the input of user\"},\n",
    "        {\"role\": \"user\", \"content\": \"I am Eduardo from Miami, United States and I speak English, also i am 2000 year old\"}\n",
    "    ],\n",
    "    max_retries=4\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Note that although the input specified an age of 2000 years, the system has defaulted to a value of 18 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nested model according to our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class SentimentEnum(str, Enum):\n",
    "    POSITIVE = \"POS\"\n",
    "    NEUTRAL = \"NEG\"\n",
    "\n",
    "class TextInfo(BaseModel):\n",
    "    sentiment: SentimentEnum = Field(description=\"The sentiment of the text\")\n",
    "    length_of_text: int = Field(description=\"The length of the text in characters\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"sentiment\": \"positive\",\n",
    "                    \"length_of_text\": 123\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_length_of_text(self) -> 'TextInfo':\n",
    "        if self.length_of_text <= 0:\n",
    "            raise ValueError('Length of text must be positive')\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': <SentimentEnum.POSITIVE: 'POS'>, 'length_of_text': 61}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=TextInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Indentifica el sentiemiento y la longitud del texto\"},\n",
    "        {\"role\": \"user\", \"content\": \"El dia de hoy fue un dia muy bueno, me siento muy feliz\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': <SentimentEnum.NEUTRAL: 'NEG'>, 'length_of_text': 54}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=TextInfo,\n",
    "    messages= [{\"role\": \"system\", \"content\": \"Indentifica el sentiemiento y la longitud del texto\"},\n",
    "        {\"role\": \"user\", \"content\": \"La verdad hoy me he sentido algo triste, no se que hacer\"}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can enforce a list of Python strings as a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class ListSchema(BaseModel):\n",
    "    feelings: List[str] = Field(description=\"A list of string items\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"feelings\": [\"happy\", \"sad\", \"angry\", \"excited\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validate_feelings(self) -> 'ListSchema':\n",
    "        if not isinstance(self.feelings, list):\n",
    "            raise ValueError('Feelings must be a list')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feelings': ['molesto', 'enojado', 'frustrado']}\n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"\"\"actua como un identificador de identidades y lista los sentimientos en los chats escritos por los usuarios\n",
    "solo identifica las entidades en el texto\n",
    "\"\"\"\n",
    "\n",
    "prompt_user = \"\"\"Me comunicque ayer para si me podrian ayudar con el problema de conexion pero la atencion no fue nada buena, estoy muy molesto y enojado,\n",
    "luego me pasaron a otro operador y luego otro, la verdad terminé frustrado\n",
    "\"\"\"\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=ListSchema,\n",
    "    messages= [{\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt_user}\n",
    "    ],\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice, we can restrict our output to a list of feelings in Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionTestRequest(BaseModel):\n",
    "    function_name: str = Field(description=\"The name of the function to be tested\")\n",
    "    input_parameters: dict = Field(description=\"A dictionary of input parameters for the function\")\n",
    "    expected_output: Union[str, int, float, bool, list, dict] = Field(description=\"The expected output of the function\")\n",
    "    description: str = Field(description=\"A brief description of the test case\")\n",
    "    code: str = Field(description=\"The code to be tested\")\n",
    "\n",
    "    model_config: ClassVar[dict] = {\n",
    "        \"json_schema_extra\": {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"function_name\": \"add\",\n",
    "                    \"input_parameters\": {\"a\": 1, \"b\": 2},\n",
    "                    \"expected_output\": 3,\n",
    "                    \"description\": \"Test case for adding two numbers\",\n",
    "                    \"code\": \"def add(a, b):\\n    return a + b\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function_name': 'multiply', 'input_parameters': {'a': 2, 'b': 3}, 'expected_output': 6, 'description': 'Test case for multiplying two numbers', 'code': 'def multiply(a, b):\\n    return a * b'}\n"
     ]
    }
   ],
   "source": [
    "prompt_system = \"\"\"Eres un experto programador de python encargado de escribir pruebas unitarias para una funciones de acuerdo a al requerimiento\n",
    "definido por el usuario\n",
    "\"\"\"\n",
    "\n",
    "prompt_user = \"\"\"Escribe una prueba unitaria para la función que multiplica dos numeros\n",
    "\"\"\"\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=FunctionTestRequest,\n",
    "    messages= [{\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": prompt_user}\n",
    "    ],\n",
    "    max_retries=4\n",
    ")\n",
    "\n",
    "print(user_info.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def multiply(a, b):\\n    return a * b'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objetivo1=user_info.model_dump()\n",
    "objetivo1['code']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
